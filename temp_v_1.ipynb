{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "\n",
    "# Loading Dataset\n",
    "file_path = 'Clothing_Shoes_and_Jewelry_5.json.gz'\n",
    "\n",
    "\n",
    "def read_json_gz_in_chunks(file_path, chunk_size=100000): #    1000000):\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "        chunk = []\n",
    "        for i, line in enumerate(f):\n",
    "            chunk.append(json.loads(line))\n",
    "            if (i + 1) % chunk_size == 0:\n",
    "                yield pd.DataFrame(chunk)\n",
    "                break\n",
    "        # if chunk:\n",
    "        #     yield pd.DataFrame(chunk)\n",
    "        # if \n",
    "\n",
    "# Initializing an empty DataFrame to concatenate chunks\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Read and process in chunks\n",
    "for chunk_df in read_json_gz_in_chunks(file_path):\n",
    "    df = pd.concat([df, chunk_df], ignore_index=True)\n",
    "\n",
    "del(chunk_df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = df[['overall', 'reviewerID', 'asin', 'reviewText']]\n",
    "reviews_df = reviews_df.dropna()\n",
    "\n",
    "# change column names of reviews_df\n",
    "reviews_df.columns = ['rating', 'user-id', 'product-id', 'review']\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(reviews_df['review'].str.len(), bins=40, edgecolor = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Function to compute sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Apply sentiment analysis\n",
    "reviews_df['sentiment'] = reviews_df['review'].apply(get_sentiment)\n",
    "\n",
    "# Aggregate reviews and average sentiment for each product\n",
    "aggregated = reviews_df.groupby('product-id').agg({\n",
    "    'review': lambda x: ' '.join(x),\n",
    "    'rating': 'mean',\n",
    "    'sentiment': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Display the first few rows of the aggregated dataset\n",
    "print(aggregated.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Convert the reviews to embeddings in batches\n",
    "def batch_embed_texts(texts, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        batch_embeddings = model.encode(batch, convert_to_tensor=True)\n",
    "        if torch.cuda.is_available():\n",
    "            batch_embeddings = batch_embeddings.cpu()  # Move to CPU if using GPU\n",
    "        embeddings.extend(batch_embeddings.numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "aggregated['review_embedding'] = list(batch_embed_texts(aggregated['review'].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_products(query, aggregated_df, top_n=15):\n",
    "    # Convert the query to an embedding\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    if torch.cuda.is_available():\n",
    "        query_embedding = query_embedding.cpu()  # Move to CPU if using GPU\n",
    "    query_embedding = query_embedding.numpy()\n",
    "    \n",
    "    # Calculate the cosine similarity between the query and each review\n",
    "    similarities = []\n",
    "    for embedding in aggregated_df['review_embedding']:\n",
    "        similarity = cosine_similarity([query_embedding], [embedding])[0][0]\n",
    "        similarities.append(similarity)\n",
    "    aggregated_df['similarity'] = similarities\n",
    "    \n",
    "    # Combine similarity with sentiment score\n",
    "    aggregated_df['final_score'] = aggregated_df['similarity'] * aggregated_df['sentiment']\n",
    "    \n",
    "    # Sort the products by final score and rating\n",
    "    recommendations = aggregated_df.sort_values(by=['final_score', 'rating'], ascending=False)\n",
    "    \n",
    "    # Select the top N recommended products\n",
    "    top_recommendations = recommendations.head(top_n)\n",
    "    \n",
    "    return top_recommendations[['product-id', 'rating', 'review', 'similarity', 'sentiment', 'final_score']]\n",
    "\n",
    "# Example query\n",
    "query = \"nice kids books\"\n",
    "\n",
    "# Get the top 5 recommendations\n",
    "top_recommendations = recommend_products(query, aggregated)\n",
    "print(top_recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_recommendations['product-id'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(reviews_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
